import { describe, expect, test, it } from '@jest/globals';
import { toDocId, TTableRequest } from '../dynamodb';
import { Table } from 'dynamodb-toolbox';
import { pBatchWrite } from './pBatchWrite';
import { customAlphabet } from 'nanoid';
import pSleep from 'p-sleep';
import chalk from 'chalk';

const BASE_62 = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz';

export const nanoid = customAlphabet(BASE_62, 10);

const config = {
  batchSize: 5,
  concurrency: 5,
  maxBackoff: 50,
  retryBackoff: 10
};

// ----------------------------------------------------------------------
//                                Tests
// ----------------------------------------------------------------------

describe('Test pBatchWrite', () => {

  // -----------------------------------------------------------

  it('should be a function', async () => {
    expect(typeof pBatchWrite)
      .toBe('function');
  });

  // -----------------------------------------------------------

  it('should return an object', async () => {
    const table = TestTable({ minSleep: 3, maxSleep: 5 });
    const results = await pBatchWrite(table, [], config);

    expect(results).toEqual({
      saved: [],
      failed: [],
      errors: [],
      batches: [],
      retries: 0,
    });
  });

  // -----------------------------------------------------------

  it('should return saved array', async () => {
    const table = TestTable({ minSleep: 3, maxSleep: 5 });
    const docs = TestDocs(15);
    const results = await pBatchWrite(table, docs, config);

    expect(results.saved).toEqual(
      expect.arrayContaining(
        docs.map(toDocId)
      )
    );
    expect(results.failed).toEqual([]);
    expect(results.errors).toEqual([]);
    expect(results.batches.length).toEqual(3);
    expect(results.retries).toEqual(0);
  });

  // -----------------------------------------------------------

  test.each([
    { concurrency: 1 },
    { concurrency: 5 },
    { concurrency: 50 }
  ])('should process in batches (concurrency = x)', async (opts) => {
    const table = TestTable({ minSleep: 3, maxSleep: 5 });
    const docs = TestDocs(50);
    const results = await pBatchWrite(table, docs, {
      ...config,
      ...opts
    });

    expect(results.saved).toEqual(
      expect.arrayContaining(
        docs.map(toDocId)
      )
    );
    expect(results.failed).toEqual([]);
    expect(results.errors).toEqual([]);
    expect(results.batches.length).toEqual(10);
    expect(results.retries).toEqual(0);
  });

  // -----------------------------------------------------------

  test.each([
    { docCount: 50, batchErrors: 5, batches: 12, retries: 2, errors: 2, failed: 0 },
    { docCount: 100, batchErrors: 6, batches: 23, retries: 3, errors: 3, failed: 0 },
  ])('should retry on retryable batch error', async (opts) => {
    const table = TestTable({
      minSleep: 3,
      maxSleep: 5,
      batchErrors: opts.batchErrors,
      retryable: true,
      //debug: true,
    });
    const docs = TestDocs(opts.docCount);
    const results = await pBatchWrite(table, docs, {
      ...config,
      maxBackoff: 30,
      retryBackoff: 2
    });

    expect(results.saved).toHaveLength(docs.length);
    //expect(results.retries).toEqual(opts.retries);
    //expect(results.batches).toEqual(opts.batches);
    expect(results.errors).toHaveLength(opts.errors);
    expect(results.failed).toHaveLength(opts.failed);
  });

  // -----------------------------------------------------------

  test.each([
    { docCount: 50, docErrors: 5, batches: 12, retries: 2, errors: 2, failed: 0 },
    { docCount: 200, docErrors: 20, batches: 23, retries: 3, errors: 3, failed: 0 },
  ])('should retry on retryable doc errors', async (opts) => {
    const table = TestTable({
      minSleep: 3,
      maxSleep: 5,
      docErrors: opts.docErrors,
      retryable: true,
      //debug: true,
    });
    const docs = TestDocs(opts.docCount);
    const results = await pBatchWrite(table, docs, {
      ...config,
      concurrency: 10,
      maxBackoff: 30,
      retryBackoff: 2
    });

    expect(results.saved).toHaveLength(docs.length);
    //expect(results.retries).toEqual(opts.retries);
    //expect(results.batches).toEqual(opts.batches);
    //expect(results.errors).toHaveLength(opts.errors);
    expect(results.failed).toHaveLength(opts.failed);
  });

  /**
   * TEST
   */
  //  it('should return errors when more than maxRetries', async () => {
  //   const sources = TestDocs(1000);

  //   const results = await pBatchWrite(sources, cbThrow, {
  //     batchSize: 10,
  //     concurrency: 10,
  //     maxRetries: 3,
  //     retryBackoff: 10
  //   });

  //   expect(results.length).toEqual(1000);
  //   expect(results.filter(r => r.status === 'error').length).toBeGreaterThan(1);
  //   expect(results.filter(r => r.status !== 'error').length).toBeGreaterThan(1);
  // });
});

// ----------------------------------------------------------------------
//                              Mocks
// ----------------------------------------------------------------------

function TestTable(
  opts: {
    minSleep?: number,
    maxSleep?: number,
    docErrors?: number,
    batchErrors?: number,
    retryable?: boolean,
    debug?: boolean
  }
): Table<string, string, string> {
  const {
    minSleep = 1,
    maxSleep = 5,
    docErrors = 0,
    batchErrors = 0,
    retryable = true,
    debug = false
  } = opts;
  let totalCount = 0;
  let docCount = 0;

  async function batchWrite(
    items: any,
    options: any
  ): Promise<any> {
    const batchCount = ++totalCount;
    const docIds = items.map(toDocId);
    const sleepFor = randInt(minSleep, maxSleep);
    const UnprocessedItems = {};
    const willThrow = (batchErrors === 1
      || (batchErrors > 1 && (!(batchCount % batchErrors)))
    );

    if (debug) {
      console.log(
        chalk.greenBright('BATCH_WRITE'), chalk.yellow(batchCount),
        'throw:', chalk.yellow(willThrow),
        'sleep:', chalk.yellow(sleepFor)
        //docIds
      );
    }

    await pSleep(sleepFor);

    if (willThrow) {
      throw {
        message: `Error for batch: ${batchCount}`,
        code: 400,
        statusCode: 400,
        retryable,
        retryBackoff: 1
      };
    }
    if (docErrors) {
      items.forEach(item => {
        if (!(++docCount % docErrors)) {
          const [table, doc] = Object.entries(item)[0];
          let docs = UnprocessedItems[table];

          if (!docs) {
            UnprocessedItems[table] = docs = [];
          }
          docs.push(doc);
        }
      });
    }

    return {
      UnprocessedItems,
      ConsumedCapacity: [{
        TableName: 'table-name',
        CapacityUnits: 3
      }]
    };
  }
  const table = { batchWrite } as Table<string, string, string>;

  return table;
}

/**
 * Create Documents
 */
function TestDocs(total: number): TTableRequest[] {
  const sources: any[] = [];
  const repoId = nanoid();

  for (let i = 0; i < total; i++) {
    sources.push({
      "table-name": {
        "PutRequest": {
          "Item": {
            "_et": "Document",
            "pk": `REPO#${repoId}`,
            "sk": `DOC#doc/${nanoid()}`,
            "version": 13,
            "status": "",
            "encoding": "json",
            "data": "{\"hello\":\"world\"}",
            "updatedOn": 1647574080121
          }
        }
      }
    });
  }
  return sources;
}

// --------------------------------------------------------------
//                      Helper Functions
// --------------------------------------------------------------

/**
 * Get Random Int >= 0 && < max
 */
function randInt(min: number, max: number): number {
  return Math.floor(Math.random() * (max - min + 1)) + min;
}


function sortSources(sources: any[]): any[] {
  return sources.sort((a, b) => a.data - b.data);
}
